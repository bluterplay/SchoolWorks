{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de ambiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de módulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:21:05.030662Z",
     "start_time": "2020-10-23T01:21:04.080179Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:17:37.593737Z",
     "iopub.status.busy": "2021-10-21T02:17:37.593095Z",
     "iopub.status.idle": "2021-10-21T02:17:37.598553Z",
     "shell.execute_reply": "2021-10-21T02:17:37.597664Z",
     "shell.execute_reply.started": "2021-10-21T02:17:37.593702Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Lars, ElasticNet, Lasso, Ridge, BayesianRidge\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: \"{:,.5f}\".format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:21:39.519651Z",
     "start_time": "2020-10-23T01:21:39.482650Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T01:47:40.965525Z",
     "iopub.status.busy": "2021-10-21T01:47:40.964757Z",
     "iopub.status.idle": "2021-10-21T01:47:41.229988Z",
     "shell.execute_reply": "2021-10-21T01:47:41.229093Z",
     "shell.execute_reply.started": "2021-10-21T01:47:40.965444Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this case special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows:\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and:\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "boston = load_boston()\n",
    "dc_scores = {}\n",
    "df = pd.DataFrame(data = boston[\"data\"], columns=boston[\"feature_names\"])\n",
    "df[\"target\"] = boston[\"target\"]\n",
    "tgt = \"target\"\n",
    "ls_pred = [x for x in df.columns if x not in [tgt]]\n",
    "X = df[ls_pred]\n",
    "y = df[tgt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:22:25.190496Z",
     "start_time": "2020-10-23T01:22:25.186735Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T01:47:41.231288Z",
     "iopub.status.busy": "2021-10-21T01:47:41.231004Z",
     "iopub.status.idle": "2021-10-21T01:47:41.238062Z",
     "shell.execute_reply": "2021-10-21T01:47:41.236544Z",
     "shell.execute_reply.started": "2021-10-21T01:47:41.231253Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(boston[\"DESCR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:25:09.022519Z",
     "start_time": "2020-10-23T01:25:09.017926Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T01:52:30.961082Z",
     "iopub.status.busy": "2021-10-21T01:52:30.960795Z",
     "iopub.status.idle": "2021-10-21T01:52:30.974281Z",
     "shell.execute_reply": "2021-10-21T01:52:30.973344Z",
     "shell.execute_reply.started": "2021-10-21T01:52:30.961051Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T01:52:42.520431Z",
     "iopub.status.busy": "2021-10-21T01:52:42.519475Z",
     "iopub.status.idle": "2021-10-21T01:52:42.611199Z",
     "shell.execute_reply": "2021-10-21T01:52:42.610526Z",
     "shell.execute_reply.started": "2021-10-21T01:52:42.520356Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>18.00</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.54</td>\n",
       "      <td>6.58</td>\n",
       "      <td>65.20</td>\n",
       "      <td>4.09</td>\n",
       "      <td>1.00</td>\n",
       "      <td>296.00</td>\n",
       "      <td>15.30</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>6.42</td>\n",
       "      <td>78.90</td>\n",
       "      <td>4.97</td>\n",
       "      <td>2.00</td>\n",
       "      <td>242.00</td>\n",
       "      <td>17.80</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>7.18</td>\n",
       "      <td>61.10</td>\n",
       "      <td>4.97</td>\n",
       "      <td>2.00</td>\n",
       "      <td>242.00</td>\n",
       "      <td>17.80</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>7.00</td>\n",
       "      <td>45.80</td>\n",
       "      <td>6.06</td>\n",
       "      <td>3.00</td>\n",
       "      <td>222.00</td>\n",
       "      <td>18.70</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>7.15</td>\n",
       "      <td>54.20</td>\n",
       "      <td>6.06</td>\n",
       "      <td>3.00</td>\n",
       "      <td>222.00</td>\n",
       "      <td>18.70</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CRIM    ZN  INDUS  CHAS  NOX   RM   AGE  DIS  RAD    TAX  PTRATIO      B  \\\n",
       "0  0.01 18.00   2.31  0.00 0.54 6.58 65.20 4.09 1.00 296.00    15.30 396.90   \n",
       "1  0.03  0.00   7.07  0.00 0.47 6.42 78.90 4.97 2.00 242.00    17.80 396.90   \n",
       "2  0.03  0.00   7.07  0.00 0.47 7.18 61.10 4.97 2.00 242.00    17.80 392.83   \n",
       "3  0.03  0.00   2.18  0.00 0.46 7.00 45.80 6.06 3.00 222.00    18.70 394.63   \n",
       "4  0.07  0.00   2.18  0.00 0.46 7.15 54.20 6.06 3.00 222.00    18.70 396.90   \n",
       "\n",
       "   LSTAT  target  \n",
       "0   4.98   24.00  \n",
       "1   9.14   21.60  \n",
       "2   4.03   34.70  \n",
       "3   2.94   33.40  \n",
       "4   5.33   36.20  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:25:23.884071Z",
     "start_time": "2020-10-23T01:25:23.880619Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T01:54:37.182788Z",
     "iopub.status.busy": "2021-10-21T01:54:37.182533Z",
     "iopub.status.idle": "2021-10-21T01:54:37.186184Z",
     "shell.execute_reply": "2021-10-21T01:54:37.185677Z",
     "shell.execute_reply.started": "2021-10-21T01:54:37.182754Z"
    }
   },
   "outputs": [],
   "source": [
    "linreg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:25:25.392585Z",
     "start_time": "2020-10-23T01:25:25.272707Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T01:54:42.734836Z",
     "iopub.status.busy": "2021-10-21T01:54:42.733397Z",
     "iopub.status.idle": "2021-10-21T01:54:43.714304Z",
     "shell.execute_reply": "2021-10-21T01:54:43.713294Z",
     "shell.execute_reply.started": "2021-10-21T01:54:42.734676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:25:29.177964Z",
     "start_time": "2020-10-23T01:25:27.953827Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T01:58:09.627618Z",
     "iopub.status.busy": "2021-10-21T01:58:09.626983Z",
     "iopub.status.idle": "2021-10-21T01:58:10.450227Z",
     "shell.execute_reply": "2021-10-21T01:58:10.448817Z",
     "shell.execute_reply.started": "2021-10-21T01:58:09.627549Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ls_res = cross_val_score(estimator = linreg, X=X, y=y, cv=4, n_jobs=-1, scoring=\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:25:53.972454Z",
     "start_time": "2020-10-23T01:25:53.967442Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T01:58:10.452974Z",
     "iopub.status.busy": "2021-10-21T01:58:10.452572Z",
     "iopub.status.idle": "2021-10-21T01:58:10.461864Z",
     "shell.execute_reply": "2021-10-21T01:58:10.460650Z",
     "shell.execute_reply.started": "2021-10-21T01:58:10.452921Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.60217169,  0.60398145,  0.35873597, -1.10867706])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:25:34.333799Z",
     "start_time": "2020-10-23T01:25:34.328295Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T01:58:12.662602Z",
     "iopub.status.busy": "2021-10-21T01:58:12.659312Z",
     "iopub.status.idle": "2021-10-21T01:58:12.687104Z",
     "shell.execute_reply": "2021-10-21T01:58:12.683811Z",
     "shell.execute_reply.started": "2021-10-21T01:58:12.662483Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11405301290101522, 0.712956573713099)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ls_res), np.std(ls_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:26:12.142795Z",
     "start_time": "2020-10-23T01:26:12.129184Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T01:58:43.028038Z",
     "iopub.status.busy": "2021-10-21T01:58:43.026557Z",
     "iopub.status.idle": "2021-10-21T01:58:43.051804Z",
     "shell.execute_reply": "2021-10-21T01:58:43.048008Z",
     "shell.execute_reply.started": "2021-10-21T01:58:43.027926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.45948838508978"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:26:13.526019Z",
     "start_time": "2020-10-23T01:26:13.521108Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T01:59:51.943644Z",
     "iopub.status.busy": "2021-10-21T01:59:51.942553Z",
     "iopub.status.idle": "2021-10-21T01:59:51.958651Z",
     "shell.execute_reply": "2021-10-21T01:59:51.957429Z",
     "shell.execute_reply.started": "2021-10-21T01:59:51.943588Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOX</td>\n",
       "      <td>-17.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DIS</td>\n",
       "      <td>-1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>-0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>-0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIM</td>\n",
       "      <td>-0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TAX</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGE</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDUS</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZN</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RAD</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHAS</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RM</td>\n",
       "      <td>3.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1\n",
       "4       NOX -17.77\n",
       "7       DIS  -1.48\n",
       "10  PTRATIO  -0.95\n",
       "12    LSTAT  -0.52\n",
       "0      CRIM  -0.11\n",
       "9       TAX  -0.01\n",
       "6       AGE   0.00\n",
       "11        B   0.01\n",
       "2     INDUS   0.02\n",
       "1        ZN   0.05\n",
       "8       RAD   0.31\n",
       "3      CHAS   2.69\n",
       "5        RM   3.81"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(zip(X.columns, linreg.coef_)).sort_values(by=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:26:34.715691Z",
     "start_time": "2020-10-23T01:26:34.710990Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:01:33.851581Z",
     "iopub.status.busy": "2021-10-21T02:01:33.850644Z",
     "iopub.status.idle": "2021-10-21T02:01:33.864549Z",
     "shell.execute_reply": "2021-10-21T02:01:33.862906Z",
     "shell.execute_reply.started": "2021-10-21T02:01:33.851446Z"
    }
   },
   "outputs": [],
   "source": [
    "dc_scores.update({str(linreg).split(\"(\")[0]: np.mean(ls_res)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:27:01.110340Z",
     "start_time": "2020-10-23T01:27:01.103144Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:01:38.827912Z",
     "iopub.status.busy": "2021-10-21T02:01:38.826685Z",
     "iopub.status.idle": "2021-10-21T02:01:38.856060Z",
     "shell.execute_reply": "2021-10-21T02:01:38.851912Z",
     "shell.execute_reply.started": "2021-10-21T02:01:38.827742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LinearRegression'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(linreg).split(\"(\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:26:35.232839Z",
     "start_time": "2020-10-23T01:26:35.223803Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:01:40.235918Z",
     "iopub.status.busy": "2021-10-21T02:01:40.234771Z",
     "iopub.status.idle": "2021-10-21T02:01:40.250870Z",
     "shell.execute_reply": "2021-10-21T02:01:40.248639Z",
     "shell.execute_reply.started": "2021-10-21T02:01:40.235784Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearRegression': 0.11405301290101522}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión LARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:32:37.198767Z",
     "start_time": "2020-10-23T01:32:37.195638Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:04:25.297714Z",
     "iopub.status.busy": "2021-10-21T02:04:25.297011Z",
     "iopub.status.idle": "2021-10-21T02:04:25.301657Z",
     "shell.execute_reply": "2021-10-21T02:04:25.300817Z",
     "shell.execute_reply.started": "2021-10-21T02:04:25.297658Z"
    }
   },
   "outputs": [],
   "source": [
    "larsreg = Lars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:32:39.110610Z",
     "start_time": "2020-10-23T01:32:39.004379Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:04:31.279711Z",
     "iopub.status.busy": "2021-10-21T02:04:31.279193Z",
     "iopub.status.idle": "2021-10-21T02:04:31.716045Z",
     "shell.execute_reply": "2021-10-21T02:04:31.712845Z",
     "shell.execute_reply.started": "2021-10-21T02:04:31.279647Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Lars()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "larsreg = larsreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:33:40.552247Z",
     "start_time": "2020-10-23T01:33:39.570797Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:05:30.264897Z",
     "iopub.status.busy": "2021-10-21T02:05:30.264633Z",
     "iopub.status.idle": "2021-10-21T02:05:31.506341Z",
     "shell.execute_reply": "2021-10-21T02:05:31.505032Z",
     "shell.execute_reply.started": "2021-10-21T02:05:30.264865Z"
    }
   },
   "outputs": [],
   "source": [
    "ls_res = cross_val_score(estimator = larsreg, X=X, y=y, cv=4, n_jobs=-1, scoring=\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T02:05:55.316503Z",
     "iopub.status.busy": "2021-10-21T02:05:55.316254Z",
     "iopub.status.idle": "2021-10-21T02:05:55.322528Z",
     "shell.execute_reply": "2021-10-21T02:05:55.321864Z",
     "shell.execute_reply.started": "2021-10-21T02:05:55.316476Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.6015054 ,  0.60398145,  0.35873597, -1.10867706])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:33:41.191510Z",
     "start_time": "2020-10-23T01:33:41.184759Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:05:48.119362Z",
     "iopub.status.busy": "2021-10-21T02:05:48.118285Z",
     "iopub.status.idle": "2021-10-21T02:05:48.127561Z",
     "shell.execute_reply": "2021-10-21T02:05:48.126713Z",
     "shell.execute_reply.started": "2021-10-21T02:05:48.119306Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11388643958845374, 0.712842580203554)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ls_res), np.std(ls_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:34:00.649686Z",
     "start_time": "2020-10-23T01:34:00.645976Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:06:08.666319Z",
     "iopub.status.busy": "2021-10-21T02:06:08.665657Z",
     "iopub.status.idle": "2021-10-21T02:06:08.672083Z",
     "shell.execute_reply": "2021-10-21T02:06:08.671071Z",
     "shell.execute_reply.started": "2021-10-21T02:06:08.666280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.95133114391082"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "larsreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:34:01.851178Z",
     "start_time": "2020-10-23T01:34:01.846149Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:06:10.393565Z",
     "iopub.status.busy": "2021-10-21T02:06:10.392192Z",
     "iopub.status.idle": "2021-10-21T02:06:10.446638Z",
     "shell.execute_reply": "2021-10-21T02:06:10.440434Z",
     "shell.execute_reply.started": "2021-10-21T02:06:10.393448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.09921668e-01,  4.77494449e-02,  3.42654195e-02,  2.67396468e+00,\n",
       "       -1.82501210e+01,  3.80245356e+00,  9.79271355e-04, -1.48628516e+00,\n",
       "        3.20424027e-01, -1.31267747e-02, -9.60367186e-01,  9.38636165e-03,\n",
       "       -5.26015958e-01])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "larsreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:34:32.330252Z",
     "start_time": "2020-10-23T01:34:32.325132Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:06:14.279639Z",
     "iopub.status.busy": "2021-10-21T02:06:14.279055Z",
     "iopub.status.idle": "2021-10-21T02:06:14.292328Z",
     "shell.execute_reply": "2021-10-21T02:06:14.290874Z",
     "shell.execute_reply.started": "2021-10-21T02:06:14.279557Z"
    }
   },
   "outputs": [],
   "source": [
    "dc_scores.update({str(larsreg).split(\"(\")[0]: np.mean(ls_res)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:34:32.736943Z",
     "start_time": "2020-10-23T01:34:32.732681Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:06:14.860560Z",
     "iopub.status.busy": "2021-10-21T02:06:14.858272Z",
     "iopub.status.idle": "2021-10-21T02:06:15.358552Z",
     "shell.execute_reply": "2021-10-21T02:06:15.356373Z",
     "shell.execute_reply.started": "2021-10-21T02:06:14.860350Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearRegression': 0.11405301290101522, 'Lars': 0.11388643958845374}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Cresta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:39:26.308599Z",
     "start_time": "2020-10-23T01:39:26.305892Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:21:35.630283Z",
     "iopub.status.busy": "2021-10-21T02:21:35.629864Z",
     "iopub.status.idle": "2021-10-21T02:21:35.635740Z",
     "shell.execute_reply": "2021-10-21T02:21:35.634749Z",
     "shell.execute_reply.started": "2021-10-21T02:21:35.630237Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ridgereg = Ridge(alpha=170)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:39:26.657521Z",
     "start_time": "2020-10-23T01:39:26.651525Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:21:35.814473Z",
     "iopub.status.busy": "2021-10-21T02:21:35.813927Z",
     "iopub.status.idle": "2021-10-21T02:21:35.828829Z",
     "shell.execute_reply": "2021-10-21T02:21:35.827492Z",
     "shell.execute_reply.started": "2021-10-21T02:21:35.814393Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=170)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgereg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:39:27.220091Z",
     "start_time": "2020-10-23T01:39:27.191070Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:21:35.983513Z",
     "iopub.status.busy": "2021-10-21T02:21:35.983069Z",
     "iopub.status.idle": "2021-10-21T02:21:36.036325Z",
     "shell.execute_reply": "2021-10-21T02:21:36.032867Z",
     "shell.execute_reply.started": "2021-10-21T02:21:35.983470Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ls_res = cross_val_score(estimator = ridgereg, X=X, y=y, cv=4, n_jobs=-1, scoring=\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T02:21:36.287166Z",
     "iopub.status.busy": "2021-10-21T02:21:36.286421Z",
     "iopub.status.idle": "2021-10-21T02:21:36.561616Z",
     "shell.execute_reply": "2021-10-21T02:21:36.560479Z",
     "shell.execute_reply.started": "2021-10-21T02:21:36.287095Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.58979113,  0.58231525,  0.47761264, -0.26179644])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:39:27.595004Z",
     "start_time": "2020-10-23T01:39:27.590925Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:09:28.889239Z",
     "iopub.status.busy": "2021-10-21T02:09:28.886094Z",
     "iopub.status.idle": "2021-10-21T02:09:28.924723Z",
     "shell.execute_reply": "2021-10-21T02:09:28.918579Z",
     "shell.execute_reply.started": "2021-10-21T02:09:28.889113Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.34698064785515315, 0.35426457700618036)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ls_res), np.std(ls_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:39:16.750023Z",
     "start_time": "2020-10-23T01:39:12.123633Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:11:10.728999Z",
     "iopub.status.busy": "2021-10-21T02:11:10.728285Z",
     "iopub.status.idle": "2021-10-21T02:11:18.413659Z",
     "shell.execute_reply": "2021-10-21T02:11:18.412516Z",
     "shell.execute_reply.started": "2021-10-21T02:11:10.728930Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 11.41% 0.71\n",
      "5 20.01% 0.61\n",
      "10 22.43% 0.57\n",
      "15 24.22% 0.55\n",
      "20 25.67% 0.53\n",
      "25 26.89% 0.51\n",
      "30 27.92% 0.49\n",
      "35 28.81% 0.48\n",
      "40 29.58% 0.47\n",
      "45 30.25% 0.46\n",
      "50 30.84% 0.45\n",
      "55 31.35% 0.44\n",
      "60 31.79% 0.43\n",
      "65 32.19% 0.42\n",
      "70 32.53% 0.41\n",
      "75 32.84% 0.41\n",
      "80 33.10% 0.40\n",
      "85 33.34% 0.40\n",
      "90 33.55% 0.39\n",
      "95 33.73% 0.39\n",
      "100 33.89% 0.39\n",
      "105 34.02% 0.38\n",
      "110 34.15% 0.38\n",
      "115 34.25% 0.38\n",
      "120 34.34% 0.37\n",
      "125 34.42% 0.37\n",
      "130 34.48% 0.37\n",
      "135 34.54% 0.37\n",
      "140 34.58% 0.36\n",
      "145 34.62% 0.36\n",
      "150 34.65% 0.36\n",
      "155 34.67% 0.36\n",
      "160 34.69% 0.36\n",
      "165 34.69% 0.36\n",
      "170 34.70% 0.35\n",
      "175 34.70% 0.35\n",
      "180 34.69% 0.35\n",
      "185 34.68% 0.35\n",
      "190 34.67% 0.35\n",
      "195 34.65% 0.35\n",
      "200 34.63% 0.35\n",
      "205 34.61% 0.35\n",
      "210 34.58% 0.35\n",
      "215 34.55% 0.35\n",
      "220 34.52% 0.35\n",
      "225 34.49% 0.35\n",
      "230 34.46% 0.34\n",
      "235 34.42% 0.34\n",
      "240 34.38% 0.34\n",
      "245 34.35% 0.34\n",
      "250 34.31% 0.34\n",
      "255 34.26% 0.34\n",
      "260 34.22% 0.34\n",
      "265 34.18% 0.34\n",
      "270 34.14% 0.34\n",
      "275 34.09% 0.34\n",
      "280 34.05% 0.34\n",
      "285 34.00% 0.34\n",
      "290 33.95% 0.34\n",
      "295 33.91% 0.34\n",
      "300 33.86% 0.34\n",
      "305 33.81% 0.34\n",
      "310 33.76% 0.34\n",
      "315 33.72% 0.34\n",
      "320 33.67% 0.34\n",
      "325 33.62% 0.34\n",
      "330 33.57% 0.34\n",
      "335 33.52% 0.34\n",
      "340 33.47% 0.34\n",
      "345 33.42% 0.34\n",
      "350 33.37% 0.34\n",
      "355 33.32% 0.34\n",
      "360 33.27% 0.34\n",
      "365 33.22% 0.34\n",
      "370 33.18% 0.34\n",
      "375 33.13% 0.34\n",
      "380 33.08% 0.34\n",
      "385 33.03% 0.34\n",
      "390 32.98% 0.34\n",
      "395 32.93% 0.34\n",
      "400 32.88% 0.34\n",
      "405 32.83% 0.34\n",
      "410 32.78% 0.34\n",
      "415 32.74% 0.34\n",
      "420 32.69% 0.34\n",
      "425 32.64% 0.34\n",
      "430 32.59% 0.34\n",
      "435 32.55% 0.34\n",
      "440 32.50% 0.34\n",
      "445 32.45% 0.34\n",
      "450 32.41% 0.34\n",
      "455 32.36% 0.34\n",
      "460 32.31% 0.34\n",
      "465 32.27% 0.34\n",
      "470 32.22% 0.33\n",
      "475 32.18% 0.33\n",
      "480 32.13% 0.33\n",
      "485 32.09% 0.33\n",
      "490 32.04% 0.33\n",
      "495 32.00% 0.33\n",
      "500 31.95% 0.33\n",
      "505 31.91% 0.33\n",
      "510 31.86% 0.33\n",
      "515 31.82% 0.33\n",
      "520 31.78% 0.33\n",
      "525 31.73% 0.33\n",
      "530 31.69% 0.33\n",
      "535 31.65% 0.33\n",
      "540 31.61% 0.33\n",
      "545 31.57% 0.33\n",
      "550 31.52% 0.33\n",
      "555 31.48% 0.33\n",
      "560 31.44% 0.33\n",
      "565 31.40% 0.33\n",
      "570 31.36% 0.33\n",
      "575 31.32% 0.33\n",
      "580 31.28% 0.33\n",
      "585 31.24% 0.33\n",
      "590 31.20% 0.33\n",
      "595 31.16% 0.33\n",
      "600 31.12% 0.33\n",
      "605 31.08% 0.33\n",
      "610 31.05% 0.33\n",
      "615 31.01% 0.33\n",
      "620 30.97% 0.33\n",
      "625 30.93% 0.33\n",
      "630 30.89% 0.33\n",
      "635 30.86% 0.33\n",
      "640 30.82% 0.33\n",
      "645 30.78% 0.33\n",
      "650 30.75% 0.33\n",
      "655 30.71% 0.33\n",
      "660 30.68% 0.33\n",
      "665 30.64% 0.33\n",
      "670 30.60% 0.33\n",
      "675 30.57% 0.33\n",
      "680 30.53% 0.33\n",
      "685 30.50% 0.33\n",
      "690 30.46% 0.33\n",
      "695 30.43% 0.33\n",
      "700 30.40% 0.33\n",
      "705 30.36% 0.33\n",
      "710 30.33% 0.33\n",
      "715 30.30% 0.33\n",
      "720 30.26% 0.33\n",
      "725 30.23% 0.33\n",
      "730 30.20% 0.33\n",
      "735 30.16% 0.33\n",
      "740 30.13% 0.33\n",
      "745 30.10% 0.33\n",
      "750 30.07% 0.33\n",
      "755 30.04% 0.33\n",
      "760 30.01% 0.33\n",
      "765 29.97% 0.33\n",
      "770 29.94% 0.33\n",
      "775 29.91% 0.32\n",
      "780 29.88% 0.32\n",
      "785 29.85% 0.32\n",
      "790 29.82% 0.32\n",
      "795 29.79% 0.32\n",
      "800 29.76% 0.32\n",
      "805 29.73% 0.32\n",
      "810 29.70% 0.32\n",
      "815 29.67% 0.32\n",
      "820 29.64% 0.32\n",
      "825 29.62% 0.32\n",
      "830 29.59% 0.32\n",
      "835 29.56% 0.32\n",
      "840 29.53% 0.32\n",
      "845 29.50% 0.32\n",
      "850 29.47% 0.32\n",
      "855 29.45% 0.32\n",
      "860 29.42% 0.32\n",
      "865 29.39% 0.32\n",
      "870 29.36% 0.32\n",
      "875 29.34% 0.32\n",
      "880 29.31% 0.32\n",
      "885 29.28% 0.32\n",
      "890 29.26% 0.32\n",
      "895 29.23% 0.32\n",
      "900 29.20% 0.32\n",
      "905 29.18% 0.32\n",
      "910 29.15% 0.32\n",
      "915 29.13% 0.32\n",
      "920 29.10% 0.32\n",
      "925 29.07% 0.32\n",
      "930 29.05% 0.32\n",
      "935 29.02% 0.32\n",
      "940 29.00% 0.32\n",
      "945 28.97% 0.32\n",
      "950 28.95% 0.32\n",
      "955 28.92% 0.32\n",
      "960 28.90% 0.32\n",
      "965 28.88% 0.32\n",
      "970 28.85% 0.32\n",
      "975 28.83% 0.32\n",
      "980 28.80% 0.32\n",
      "985 28.78% 0.31\n",
      "990 28.76% 0.31\n",
      "995 28.73% 0.31\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 1000, 5):\n",
    "    ridgereg = Ridge(alpha=i)\n",
    "    ridgereg.fit(X, y)\n",
    "    ls_res = cross_val_score(estimator = ridgereg, X=X, y=y, cv=4, n_jobs=-1, scoring=\"r2\")\n",
    "    print(i, \"{:,.2%}\".format(np.mean(ls_res)), \"{:,.2f}\".format(np.std(ls_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:39:33.964463Z",
     "start_time": "2020-10-23T01:39:33.958739Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:13:07.693035Z",
     "iopub.status.busy": "2021-10-21T02:13:07.692522Z",
     "iopub.status.idle": "2021-10-21T02:13:07.700189Z",
     "shell.execute_reply": "2021-10-21T02:13:07.699170Z",
     "shell.execute_reply.started": "2021-10-21T02:13:07.692981Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.526619339976584"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgereg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:39:34.923556Z",
     "start_time": "2020-10-23T01:39:34.917994Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:13:38.618017Z",
     "iopub.status.busy": "2021-10-21T02:13:38.617373Z",
     "iopub.status.idle": "2021-10-21T02:13:38.641462Z",
     "shell.execute_reply": "2021-10-21T02:13:38.640166Z",
     "shell.execute_reply.started": "2021-10-21T02:13:38.617938Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DIS</td>\n",
       "      <td>-1.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>-0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>-0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOX</td>\n",
       "      <td>-0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIM</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDUS</td>\n",
       "      <td>-0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TAX</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGE</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZN</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RAD</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHAS</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RM</td>\n",
       "      <td>1.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1\n",
       "7       DIS -1.08\n",
       "10  PTRATIO -0.83\n",
       "12    LSTAT -0.70\n",
       "4       NOX -0.15\n",
       "0      CRIM -0.10\n",
       "2     INDUS -0.05\n",
       "9       TAX -0.02\n",
       "6       AGE  0.01\n",
       "11        B  0.01\n",
       "1        ZN  0.06\n",
       "8       RAD  0.33\n",
       "3      CHAS  0.43\n",
       "5        RM  1.83"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(zip(X.columns, ridgereg.coef_)).sort_values(by=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:39:37.727759Z",
     "start_time": "2020-10-23T01:39:37.723741Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:21:52.926305Z",
     "iopub.status.busy": "2021-10-21T02:21:52.925197Z",
     "iopub.status.idle": "2021-10-21T02:21:52.933508Z",
     "shell.execute_reply": "2021-10-21T02:21:52.932549Z",
     "shell.execute_reply.started": "2021-10-21T02:21:52.926226Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dc_scores.update({str(ridgereg).split(\"(\")[0]: np.mean(ls_res)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:39:38.169489Z",
     "start_time": "2020-10-23T01:39:38.165108Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:14:59.926076Z",
     "iopub.status.busy": "2021-10-21T02:14:59.925046Z",
     "iopub.status.idle": "2021-10-21T02:14:59.943113Z",
     "shell.execute_reply": "2021-10-21T02:14:59.940764Z",
     "shell.execute_reply.started": "2021-10-21T02:14:59.925950Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearRegression': 0.11405301290101522,\n",
       " 'Lars': 0.11388643958845374,\n",
       " 'Ridge': 0.2873317855328939}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:43:33.489355Z",
     "start_time": "2020-10-23T01:43:33.485500Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:21:10.725249Z",
     "iopub.status.busy": "2021-10-21T02:21:10.724108Z",
     "iopub.status.idle": "2021-10-21T02:21:10.729544Z",
     "shell.execute_reply": "2021-10-21T02:21:10.728458Z",
     "shell.execute_reply.started": "2021-10-21T02:21:10.725209Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lassreg = Lasso(alpha=170/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:43:33.749902Z",
     "start_time": "2020-10-23T01:43:33.742002Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:21:11.024807Z",
     "iopub.status.busy": "2021-10-21T02:21:11.024485Z",
     "iopub.status.idle": "2021-10-21T02:21:11.036482Z",
     "shell.execute_reply": "2021-10-21T02:21:11.035387Z",
     "shell.execute_reply.started": "2021-10-21T02:21:11.024772Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.7)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lassreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:43:34.322856Z",
     "start_time": "2020-10-23T01:43:34.293113Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:21:17.265570Z",
     "iopub.status.busy": "2021-10-21T02:21:17.265042Z",
     "iopub.status.idle": "2021-10-21T02:21:17.312562Z",
     "shell.execute_reply": "2021-10-21T02:21:17.303696Z",
     "shell.execute_reply.started": "2021-10-21T02:21:17.265516Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ls_res = cross_val_score(estimator = lassreg, X=X, y=y, cv=4, n_jobs=-1, scoring=\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T02:21:18.738393Z",
     "iopub.status.busy": "2021-10-21T02:21:18.737096Z",
     "iopub.status.idle": "2021-10-21T02:21:18.766685Z",
     "shell.execute_reply": "2021-10-21T02:21:18.764755Z",
     "shell.execute_reply.started": "2021-10-21T02:21:18.738242Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.43962247,  0.4881991 ,  0.3038345 , -0.00741578])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:43:34.710994Z",
     "start_time": "2020-10-23T01:43:34.704672Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:16:12.700267Z",
     "iopub.status.busy": "2021-10-21T02:16:12.699975Z",
     "iopub.status.idle": "2021-10-21T02:16:12.705817Z",
     "shell.execute_reply": "2021-10-21T02:16:12.704969Z",
     "shell.execute_reply.started": "2021-10-21T02:16:12.700240Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3060600729140215, 0.19318747453416638)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ls_res), np.std(ls_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:41:30.256076Z",
     "start_time": "2020-10-23T01:41:30.252357Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:16:46.138274Z",
     "iopub.status.busy": "2021-10-21T02:16:46.137948Z",
     "iopub.status.idle": "2021-10-21T02:16:46.144270Z",
     "shell.execute_reply": "2021-10-21T02:16:46.143312Z",
     "shell.execute_reply.started": "2021-10-21T02:16:46.138241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.14580423775246"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lassreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:41:31.117302Z",
     "start_time": "2020-10-23T01:41:31.111916Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:17:42.725578Z",
     "iopub.status.busy": "2021-10-21T02:17:42.724964Z",
     "iopub.status.idle": "2021-10-21T02:17:42.745587Z",
     "shell.execute_reply": "2021-10-21T02:17:42.743748Z",
     "shell.execute_reply.started": "2021-10-21T02:17:42.725538Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>-0.82303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>-0.61916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DIS</td>\n",
       "      <td>-0.25814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIM</td>\n",
       "      <td>-0.03442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TAX</td>\n",
       "      <td>-0.01310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDUS</td>\n",
       "      <td>-0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHAS</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOX</td>\n",
       "      <td>-0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RM</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>0.00725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGE</td>\n",
       "      <td>0.03837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZN</td>\n",
       "      <td>0.04128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RAD</td>\n",
       "      <td>0.20861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0        1\n",
       "12    LSTAT -0.82303\n",
       "10  PTRATIO -0.61916\n",
       "7       DIS -0.25814\n",
       "0      CRIM -0.03442\n",
       "9       TAX -0.01310\n",
       "2     INDUS -0.00000\n",
       "3      CHAS  0.00000\n",
       "4       NOX -0.00000\n",
       "5        RM  0.00000\n",
       "11        B  0.00725\n",
       "6       AGE  0.03837\n",
       "1        ZN  0.04128\n",
       "8       RAD  0.20861"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(zip(X.columns, lassreg.coef_)).sort_values(by=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:41:47.449821Z",
     "start_time": "2020-10-23T01:41:45.057109Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:19:55.535790Z",
     "iopub.status.busy": "2021-10-21T02:19:55.535212Z",
     "iopub.status.idle": "2021-10-21T02:20:00.955068Z",
     "shell.execute_reply": "2021-10-21T02:20:00.954107Z",
     "shell.execute_reply.started": "2021-10-21T02:19:55.535739Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.539e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 11.41% 0.71\n",
      "10 19.19% 0.61\n",
      "20 21.23% 0.58\n",
      "30 20.97% 0.57\n",
      "40 20.35% 0.57\n",
      "50 21.96% 0.53\n",
      "60 23.64% 0.49\n",
      "70 25.26% 0.45\n",
      "80 26.61% 0.41\n",
      "90 27.71% 0.38\n",
      "100 28.54% 0.35\n",
      "110 29.11% 0.32\n",
      "120 29.58% 0.29\n",
      "130 29.80% 0.26\n",
      "140 30.09% 0.24\n",
      "150 30.35% 0.22\n",
      "160 30.56% 0.21\n",
      "170 30.61% 0.19\n",
      "180 30.28% 0.19\n",
      "190 29.87% 0.18\n",
      "200 29.49% 0.17\n",
      "210 29.15% 0.16\n",
      "220 28.76% 0.16\n",
      "230 28.33% 0.15\n",
      "240 28.03% 0.15\n",
      "250 27.76% 0.14\n",
      "260 27.46% 0.14\n",
      "270 27.14% 0.13\n",
      "280 26.80% 0.13\n",
      "290 26.44% 0.12\n",
      "300 26.05% 0.12\n",
      "310 25.75% 0.11\n",
      "320 25.45% 0.11\n",
      "330 25.11% 0.10\n",
      "340 24.76% 0.10\n",
      "350 24.44% 0.10\n",
      "360 24.17% 0.10\n",
      "370 24.07% 0.09\n",
      "380 24.11% 0.09\n",
      "390 24.15% 0.09\n",
      "400 24.17% 0.09\n",
      "410 24.19% 0.09\n",
      "420 24.19% 0.09\n",
      "430 24.21% 0.09\n",
      "440 24.22% 0.09\n",
      "450 24.22% 0.08\n",
      "460 24.21% 0.08\n",
      "470 24.24% 0.08\n",
      "480 24.28% 0.08\n",
      "490 24.28% 0.08\n",
      "500 24.23% 0.08\n",
      "510 24.17% 0.08\n",
      "520 24.12% 0.08\n",
      "530 24.06% 0.08\n",
      "540 23.99% 0.08\n",
      "550 23.93% 0.08\n",
      "560 23.86% 0.08\n",
      "570 23.78% 0.08\n",
      "580 23.71% 0.08\n",
      "590 23.63% 0.08\n",
      "600 23.54% 0.08\n",
      "610 23.46% 0.08\n",
      "620 23.37% 0.08\n",
      "630 23.27% 0.07\n",
      "640 23.18% 0.07\n",
      "650 23.08% 0.07\n",
      "660 22.98% 0.07\n",
      "670 22.87% 0.07\n",
      "680 22.76% 0.07\n",
      "690 22.65% 0.07\n",
      "700 22.54% 0.07\n",
      "710 22.42% 0.07\n",
      "720 22.30% 0.07\n",
      "730 22.17% 0.07\n",
      "740 22.05% 0.07\n",
      "750 21.92% 0.07\n",
      "760 21.78% 0.07\n",
      "770 21.65% 0.07\n",
      "780 21.51% 0.07\n",
      "790 21.36% 0.07\n",
      "800 21.22% 0.07\n",
      "810 21.07% 0.07\n",
      "820 20.91% 0.07\n",
      "830 20.75% 0.07\n",
      "840 20.60% 0.07\n",
      "850 20.44% 0.07\n",
      "860 20.28% 0.07\n",
      "870 20.12% 0.07\n",
      "880 19.96% 0.07\n",
      "890 19.79% 0.07\n",
      "900 19.62% 0.07\n",
      "910 19.45% 0.07\n",
      "920 19.27% 0.07\n",
      "930 19.09% 0.07\n",
      "940 18.91% 0.07\n",
      "950 18.72% 0.07\n",
      "960 18.54% 0.07\n",
      "970 18.35% 0.07\n",
      "980 18.15% 0.07\n",
      "990 17.95% 0.07\n",
      "1000 17.75% 0.07\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 1000, 10):\n",
    "    lasso = Lasso(alpha=i/100)\n",
    "    lasso.fit(X, y)\n",
    "    ls_res = cross_val_score(estimator = lasso, X=X, y=y, cv=4, n_jobs=-1, scoring=\"r2\")\n",
    "    print(i, \"{:,.2%}\".format(np.mean(ls_res)), \"{:,.2f}\".format(np.std(ls_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:43:39.389180Z",
     "start_time": "2020-10-23T01:43:39.384596Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:21:23.628153Z",
     "iopub.status.busy": "2021-10-21T02:21:23.627539Z",
     "iopub.status.idle": "2021-10-21T02:21:23.632383Z",
     "shell.execute_reply": "2021-10-21T02:21:23.631699Z",
     "shell.execute_reply.started": "2021-10-21T02:21:23.628117Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dc_scores.update({str(lassreg).split(\"(\")[0]: np.mean(ls_res)})\n",
    "\n",
    "dc_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red elástica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:51:49.187713Z",
     "start_time": "2020-10-23T01:51:49.182703Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:25:39.713410Z",
     "iopub.status.busy": "2021-10-21T02:25:39.713118Z",
     "iopub.status.idle": "2021-10-21T02:25:39.718382Z",
     "shell.execute_reply": "2021-10-21T02:25:39.717565Z",
     "shell.execute_reply.started": "2021-10-21T02:25:39.713376Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "elasnet = ElasticNet(alpha=0.5, l1_ratio=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:51:49.524607Z",
     "start_time": "2020-10-23T01:51:49.501067Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:25:39.720829Z",
     "iopub.status.busy": "2021-10-21T02:25:39.720224Z",
     "iopub.status.idle": "2021-10-21T02:25:40.249744Z",
     "shell.execute_reply": "2021-10-21T02:25:40.248644Z",
     "shell.execute_reply.started": "2021-10-21T02:25:39.720752Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.5, l1_ratio=1e-06)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasnet.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:51:50.258421Z",
     "start_time": "2020-10-23T01:51:50.234907Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:25:40.252826Z",
     "iopub.status.busy": "2021-10-21T02:25:40.251449Z",
     "iopub.status.idle": "2021-10-21T02:25:40.419951Z",
     "shell.execute_reply": "2021-10-21T02:25:40.418912Z",
     "shell.execute_reply.started": "2021-10-21T02:25:40.252750Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ls_res = cross_val_score(estimator = elasnet, X=X, y=y, cv=4, n_jobs=-1, scoring=\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T02:25:40.422822Z",
     "iopub.status.busy": "2021-10-21T02:25:40.421880Z",
     "iopub.status.idle": "2021-10-21T02:25:40.463994Z",
     "shell.execute_reply": "2021-10-21T02:25:40.462220Z",
     "shell.execute_reply.started": "2021-10-21T02:25:40.422751Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.58582377,  0.57947968,  0.47651412, -0.25495132])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:51:50.983074Z",
     "start_time": "2020-10-23T01:51:50.976892Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:23:30.206985Z",
     "iopub.status.busy": "2021-10-21T02:23:30.205996Z",
     "iopub.status.idle": "2021-10-21T02:23:30.222868Z",
     "shell.execute_reply": "2021-10-21T02:23:30.221350Z",
     "shell.execute_reply.started": "2021-10-21T02:23:30.206883Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3467165616106645, 0.35007233834607887)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ls_res), np.std(ls_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:50:48.194846Z",
     "start_time": "2020-10-23T01:50:24.080079Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:23:44.203113Z",
     "iopub.status.busy": "2021-10-21T02:23:44.202598Z",
     "iopub.status.idle": "2021-10-21T02:24:15.899285Z",
     "shell.execute_reply": "2021-10-21T02:24:15.898451Z",
     "shell.execute_reply.started": "2021-10-21T02:23:44.203055Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  \n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.539e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  \n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.539e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  \n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.539e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  \n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.539e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  \n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.539e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  \n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.539e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  \n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.539e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  \n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.539e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  \n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.539e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  \n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.539e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.199e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.456e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.642e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.694e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.884e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.694e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.694e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.694e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.694e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.143e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.251e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.332e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.028e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.028e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.726e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.726e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.726e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.726e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.429e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.723e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.914e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.791e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.916e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.884e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.884e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.884e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.884e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.884e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.488e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.677e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.818e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.053e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.160e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.024e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.121e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.694e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.694e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.694e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.694e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.694e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.093e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.249e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.377e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.248e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.582e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.209e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.290e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.726e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.028e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.028e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.028e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.028e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.932e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.462e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.193e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.263e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.328e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.884e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.694e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.884e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.884e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.884e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.884e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.322e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.386e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.663e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.365e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.435e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.501e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.726e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.028e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.028e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.028e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.028e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.609e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.892e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.388e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.444e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.496e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.563e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.623e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.679e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.734e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.786e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.836e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.401e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.030e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.486e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.569e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.617e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.443e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.494e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.540e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.583e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.622e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.860e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.895e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.173e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.757e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.786e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.885e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.932e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.977e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.021e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.669e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.747e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.820e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.887e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.951e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.546e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.659e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.693e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.682e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.223e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.271e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.814e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.841e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.406e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.448e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.064e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.105e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.146e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.726e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.028e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.726e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.726e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.726e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:681: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.726e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.489e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.529e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.568e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.185e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.224e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.706e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.747e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.787e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.824e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.723e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.992e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.317e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.838e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.874e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.909e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.942e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.975e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.007e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.213e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.003e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.262e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.298e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.334e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.369e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.404e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.594e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.639e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.726e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.867e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.108e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.915e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.938e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.961e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.982e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.237e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.261e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.285e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.307e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.330e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.209e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.438e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.471e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.503e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.535e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.023e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.052e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.081e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.891e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.135e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.162e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.188e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.038e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.068e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.098e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.126e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.154e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.182e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.352e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.943e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.567e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.597e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.628e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.657e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.605e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.642e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.679e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.044e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.749e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.783e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.816e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.118e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.136e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.416e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.170e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.456e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.476e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.495e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.514e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.687e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.715e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.517e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.067e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.121e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.929e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.961e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.235e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.261e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.286e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.436e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.187e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.203e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.219e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.062e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.090e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.551e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.744e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.772e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.799e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.826e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.116e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.763e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.801e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.362e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.714e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.063e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.082e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.100e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.395e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.452e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.474e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.496e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.173e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.200e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.227e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.853e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.880e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.906e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.931e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.957e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.982e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.006e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.031e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.849e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.881e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.912e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.311e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.336e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.360e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.538e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.337e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.351e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.365e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.378e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.391e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.404e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.738e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.427e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.055e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.079e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.102e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.126e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.149e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.171e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.194e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.253e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.279e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.304e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.329e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.354e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.379e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.403e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.753e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.769e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.474e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.467e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.479e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.491e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.503e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.514e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.216e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.238e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.260e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.281e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.303e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.324e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.344e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.974e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.003e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.734e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.497e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.520e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.542e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.843e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.857e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.871e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.885e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.875e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.892e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.909e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.582e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.953e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.010e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.033e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.235e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.250e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.118e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.146e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.517e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.678e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.430e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.442e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.651e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.560e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.927e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.925e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.735e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.365e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.450e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.784e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.753e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.814e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.828e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.564e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.587e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.608e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.630e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.548e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.672e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.693e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.940e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.592e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.755e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.386e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.406e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.426e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.446e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.465e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.485e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.504e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.523e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.024e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.153e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.406e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.429e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.579e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.600e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.690e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.706e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.722e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.417e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.645e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.655e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.043e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.066e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.081e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.542e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.561e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.280e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.295e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.309e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.623e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.640e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.657e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.673e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.620e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.639e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.659e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.973e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.624e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.853e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.695e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.705e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.580e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.598e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.374e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.383e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.697e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.716e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.455e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.799e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.771e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.789e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.806e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.966e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.979e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.992e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.005e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.125e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.115e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.617e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.635e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.653e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.775e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.795e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.005e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.020e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.036e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.665e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.675e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.685e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.929e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.948e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.966e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.140e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.002e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.743e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.752e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.671e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.533e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.265e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.570e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.587e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.605e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.323e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.559e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.824e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.841e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.858e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.984e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.126e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.138e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.149e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.160e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.688e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.706e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.603e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.614e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.989e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.815e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.018e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.030e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.873e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.892e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.910e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.079e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.091e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.103e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.055e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.771e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.780e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.723e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.740e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.758e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.775e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.791e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.808e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.825e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.841e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.858e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.874e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.890e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.906e+03, tolerance: 4.272e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.526e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.537e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.899e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.913e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.571e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.714e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.941e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.958e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.051e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.055e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.067e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.096e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.356e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.875e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.309e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    }
   ],
   "source": [
    "df_res = pd.DataFrame(columns=[\"alpha\", \"l1_ratio\", \"score\", \"std\"])\n",
    "contador = 0\n",
    "for i in range(0, 1000, 10):\n",
    "    for j in range(10):\n",
    "        elasnet = ElasticNet(alpha=i/100, l1_ratio=j/10)\n",
    "        elasnet.fit(X, y)\n",
    "        ls_res = cross_val_score(estimator = elasnet, X=X, y=y, cv=4, n_jobs=-1, scoring=\"r2\")\n",
    "        df_res.loc[contador, \"alpha\"] = i\n",
    "        df_res.loc[contador, \"l1_ratio\"] = j\n",
    "        df_res.loc[contador, \"score\"] = np.mean(ls_res)\n",
    "        df_res.loc[contador, \"std\"] = np.std(ls_res)\n",
    "        contador += 1\n",
    "#         print(i/100, j/10, \"{:,.2%}\".format(np.mean(ls_res)), \"{:,.2f}\".format(np.std(ls_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T02:24:48.928630Z",
     "iopub.status.busy": "2021-10-21T02:24:48.928154Z",
     "iopub.status.idle": "2021-10-21T02:24:48.934672Z",
     "shell.execute_reply": "2021-10-21T02:24:48.933829Z",
     "shell.execute_reply.started": "2021-10-21T02:24:48.928595Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T02:24:59.196813Z",
     "iopub.status.busy": "2021-10-21T02:24:59.195338Z",
     "iopub.status.idle": "2021-10-21T02:24:59.219454Z",
     "shell.execute_reply": "2021-10-21T02:24:59.218536Z",
     "shell.execute_reply.started": "2021-10-21T02:24:59.196714Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>l1_ratio</th>\n",
       "      <th>score</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.11405</td>\n",
       "      <td>0.71296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.11405</td>\n",
       "      <td>0.71296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.11405</td>\n",
       "      <td>0.71296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.11405</td>\n",
       "      <td>0.71296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.11405</td>\n",
       "      <td>0.71296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>990</td>\n",
       "      <td>5</td>\n",
       "      <td>0.21215</td>\n",
       "      <td>0.07710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>990</td>\n",
       "      <td>6</td>\n",
       "      <td>0.20935</td>\n",
       "      <td>0.07455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>990</td>\n",
       "      <td>7</td>\n",
       "      <td>0.20326</td>\n",
       "      <td>0.07262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>990</td>\n",
       "      <td>8</td>\n",
       "      <td>0.19611</td>\n",
       "      <td>0.07142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>990</td>\n",
       "      <td>9</td>\n",
       "      <td>0.18854</td>\n",
       "      <td>0.07227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    alpha l1_ratio   score     std\n",
       "0       0        0 0.11405 0.71296\n",
       "1       0        1 0.11405 0.71296\n",
       "2       0        2 0.11405 0.71296\n",
       "3       0        3 0.11405 0.71296\n",
       "4       0        4 0.11405 0.71296\n",
       "..    ...      ...     ...     ...\n",
       "995   990        5 0.21215 0.07710\n",
       "996   990        6 0.20935 0.07455\n",
       "997   990        7 0.20326 0.07262\n",
       "998   990        8 0.19611 0.07142\n",
       "999   990        9 0.18854 0.07227\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:51:10.021251Z",
     "start_time": "2020-10-23T01:51:09.997658Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:25:04.873211Z",
     "iopub.status.busy": "2021-10-21T02:25:04.872880Z",
     "iopub.status.idle": "2021-10-21T02:25:04.900084Z",
     "shell.execute_reply": "2021-10-21T02:25:04.898961Z",
     "shell.execute_reply.started": "2021-10-21T02:25:04.873175Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>l1_ratio</th>\n",
       "      <th>score</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.11405</td>\n",
       "      <td>0.71296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.11405</td>\n",
       "      <td>0.71296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.11405</td>\n",
       "      <td>0.71296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.11405</td>\n",
       "      <td>0.71296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.11405</td>\n",
       "      <td>0.71296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0.34176</td>\n",
       "      <td>0.34149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.34234</td>\n",
       "      <td>0.37591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.34475</td>\n",
       "      <td>0.34471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.34662</td>\n",
       "      <td>0.35932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.34672</td>\n",
       "      <td>0.35007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   alpha l1_ratio   score     std\n",
       "0      0        0 0.11405 0.71296\n",
       "1      0        1 0.11405 0.71296\n",
       "2      0        2 0.11405 0.71296\n",
       "3      0        3 0.11405 0.71296\n",
       "4      0        4 0.11405 0.71296\n",
       "..   ...      ...     ...     ...\n",
       "70    70        0 0.34176 0.34149\n",
       "30    30        0 0.34234 0.37591\n",
       "60    60        0 0.34475 0.34471\n",
       "40    40        0 0.34662 0.35932\n",
       "50    50        0 0.34672 0.35007\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res.sort_values(by = \"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:51:38.262095Z",
     "start_time": "2020-10-23T01:51:38.255926Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:25:43.732891Z",
     "iopub.status.busy": "2021-10-21T02:25:43.732623Z",
     "iopub.status.idle": "2021-10-21T02:25:43.739072Z",
     "shell.execute_reply": "2021-10-21T02:25:43.738131Z",
     "shell.execute_reply.started": "2021-10-21T02:25:43.732859Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.42139506351087"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasnet.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:51:38.521209Z",
     "start_time": "2020-10-23T01:51:38.513954Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:26:00.930192Z",
     "iopub.status.busy": "2021-10-21T02:26:00.929824Z",
     "iopub.status.idle": "2021-10-21T02:26:00.943374Z",
     "shell.execute_reply": "2021-10-21T02:26:00.942295Z",
     "shell.execute_reply.started": "2021-10-21T02:26:00.930155Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DIS</td>\n",
       "      <td>-1.00841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>-0.82171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>-0.72068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIM</td>\n",
       "      <td>-0.09995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOX</td>\n",
       "      <td>-0.09624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDUS</td>\n",
       "      <td>-0.05039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TAX</td>\n",
       "      <td>-0.01659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>0.00879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGE</td>\n",
       "      <td>0.01231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZN</td>\n",
       "      <td>0.05563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHAS</td>\n",
       "      <td>0.31288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RAD</td>\n",
       "      <td>0.33046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RM</td>\n",
       "      <td>1.46092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0        1\n",
       "7       DIS -1.00841\n",
       "10  PTRATIO -0.82171\n",
       "12    LSTAT -0.72068\n",
       "0      CRIM -0.09995\n",
       "4       NOX -0.09624\n",
       "2     INDUS -0.05039\n",
       "9       TAX -0.01659\n",
       "11        B  0.00879\n",
       "6       AGE  0.01231\n",
       "1        ZN  0.05563\n",
       "3      CHAS  0.31288\n",
       "8       RAD  0.33046\n",
       "5        RM  1.46092"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(zip(X.columns, elasnet.coef_)).sort_values(by=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:51:55.802200Z",
     "start_time": "2020-10-23T01:51:55.798708Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:27:22.147954Z",
     "iopub.status.busy": "2021-10-21T02:27:22.147613Z",
     "iopub.status.idle": "2021-10-21T02:27:22.153895Z",
     "shell.execute_reply": "2021-10-21T02:27:22.152550Z",
     "shell.execute_reply.started": "2021-10-21T02:27:22.147923Z"
    }
   },
   "outputs": [],
   "source": [
    "dc_scores.update({str(elasnet).split(\"(\")[0]: np.mean(ls_res)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:51:56.091203Z",
     "start_time": "2020-10-23T01:51:56.086699Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:27:22.514923Z",
     "iopub.status.busy": "2021-10-21T02:27:22.513877Z",
     "iopub.status.idle": "2021-10-21T02:27:22.521018Z",
     "shell.execute_reply": "2021-10-21T02:27:22.520155Z",
     "shell.execute_reply.started": "2021-10-21T02:27:22.514871Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearRegression': 0.11405301290101522,\n",
       " 'Lars': 0.11388643958845374,\n",
       " 'Ridge': 0.34698064785515315,\n",
       " 'Lasso': 0.3060600729140215,\n",
       " 'ElasticNet': 0.3467165616106645}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:52:00.732888Z",
     "start_time": "2020-10-23T01:52:00.728451Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:27:31.671737Z",
     "iopub.status.busy": "2021-10-21T02:27:31.671132Z",
     "iopub.status.idle": "2021-10-21T02:27:31.677390Z",
     "shell.execute_reply": "2021-10-21T02:27:31.675508Z",
     "shell.execute_reply.started": "2021-10-21T02:27:31.671687Z"
    }
   },
   "outputs": [],
   "source": [
    "bayreg = BayesianRidge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:52:10.794191Z",
     "start_time": "2020-10-23T01:52:10.784846Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:27:41.313942Z",
     "iopub.status.busy": "2021-10-21T02:27:41.313608Z",
     "iopub.status.idle": "2021-10-21T02:27:41.372555Z",
     "shell.execute_reply": "2021-10-21T02:27:41.371176Z",
     "shell.execute_reply.started": "2021-10-21T02:27:41.313908Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BayesianRidge()"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:52:12.440322Z",
     "start_time": "2020-10-23T01:52:12.415989Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:28:06.267429Z",
     "iopub.status.busy": "2021-10-21T02:28:06.267035Z",
     "iopub.status.idle": "2021-10-21T02:28:06.308225Z",
     "shell.execute_reply": "2021-10-21T02:28:06.307382Z",
     "shell.execute_reply.started": "2021-10-21T02:28:06.267381Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ls_res = cross_val_score(estimator = bayreg, X=X, y=y, cv=4, n_jobs=-1, scoring=\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T02:28:06.998926Z",
     "iopub.status.busy": "2021-10-21T02:28:06.994943Z",
     "iopub.status.idle": "2021-10-21T02:28:07.030713Z",
     "shell.execute_reply": "2021-10-21T02:28:07.027188Z",
     "shell.execute_reply.started": "2021-10-21T02:28:06.998694Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.64182838,  0.61663703,  0.37058843, -0.77508562])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:52:13.134439Z",
     "start_time": "2020-10-23T01:52:13.129868Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:28:08.342332Z",
     "iopub.status.busy": "2021-10-21T02:28:08.341957Z",
     "iopub.status.idle": "2021-10-21T02:28:08.350675Z",
     "shell.execute_reply": "2021-10-21T02:28:08.349045Z",
     "shell.execute_reply.started": "2021-10-21T02:28:08.342291Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.213492055305246, 0.5805090395044222)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ls_res), np.std(ls_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:52:21.139157Z",
     "start_time": "2020-10-23T01:52:21.135025Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:28:10.548666Z",
     "iopub.status.busy": "2021-10-21T02:28:10.548365Z",
     "iopub.status.idle": "2021-10-21T02:28:10.554178Z",
     "shell.execute_reply": "2021-10-21T02:28:10.553324Z",
     "shell.execute_reply.started": "2021-10-21T02:28:10.548633Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.551854857902597"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:52:22.097398Z",
     "start_time": "2020-10-23T01:52:22.092330Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:28:17.747959Z",
     "iopub.status.busy": "2021-10-21T02:28:17.747518Z",
     "iopub.status.idle": "2021-10-21T02:28:17.761777Z",
     "shell.execute_reply": "2021-10-21T02:28:17.760324Z",
     "shell.execute_reply.started": "2021-10-21T02:28:17.747921Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOX</td>\n",
       "      <td>-2.14193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DIS</td>\n",
       "      <td>-1.24523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>-0.79726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>-0.56188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIM</td>\n",
       "      <td>-0.10144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDUS</td>\n",
       "      <td>-0.04384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TAX</td>\n",
       "      <td>-0.01406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGE</td>\n",
       "      <td>-0.01062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>0.01004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZN</td>\n",
       "      <td>0.04974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RAD</td>\n",
       "      <td>0.28022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHAS</td>\n",
       "      <td>1.89485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RM</td>\n",
       "      <td>3.67401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0        1\n",
       "4       NOX -2.14193\n",
       "7       DIS -1.24523\n",
       "10  PTRATIO -0.79726\n",
       "12    LSTAT -0.56188\n",
       "0      CRIM -0.10144\n",
       "2     INDUS -0.04384\n",
       "9       TAX -0.01406\n",
       "6       AGE -0.01062\n",
       "11        B  0.01004\n",
       "1        ZN  0.04974\n",
       "8       RAD  0.28022\n",
       "3      CHAS  1.89485\n",
       "5        RM  3.67401"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(zip(X.columns, bayreg.coef_)).sort_values(by=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:52:24.894504Z",
     "start_time": "2020-10-23T01:52:24.890725Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:28:26.591056Z",
     "iopub.status.busy": "2021-10-21T02:28:26.590684Z",
     "iopub.status.idle": "2021-10-21T02:28:26.597539Z",
     "shell.execute_reply": "2021-10-21T02:28:26.596428Z",
     "shell.execute_reply.started": "2021-10-21T02:28:26.591009Z"
    }
   },
   "outputs": [],
   "source": [
    "dc_scores.update({str(bayreg).split(\"(\")[0]: np.mean(ls_res)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:52:25.453304Z",
     "start_time": "2020-10-23T01:52:25.448194Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:28:27.154215Z",
     "iopub.status.busy": "2021-10-21T02:28:27.153568Z",
     "iopub.status.idle": "2021-10-21T02:28:27.162089Z",
     "shell.execute_reply": "2021-10-21T02:28:27.160908Z",
     "shell.execute_reply.started": "2021-10-21T02:28:27.154130Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearRegression': 0.11405301290101522,\n",
       " 'Lars': 0.11388643958845374,\n",
       " 'Ridge': 0.34698064785515315,\n",
       " 'Lasso': 0.3060600729140215,\n",
       " 'ElasticNet': 0.3467165616106645,\n",
       " 'BayesianRidge': 0.213492055305246}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:52:43.760939Z",
     "start_time": "2020-10-23T01:52:43.740871Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:28:50.479920Z",
     "iopub.status.busy": "2021-10-21T02:28:50.478481Z",
     "iopub.status.idle": "2021-10-21T02:28:50.535008Z",
     "shell.execute_reply": "2021-10-21T02:28:50.534023Z",
     "shell.execute_reply.started": "2021-10-21T02:28:50.479764Z"
    }
   },
   "outputs": [],
   "source": [
    "resul = pd.DataFrame(columns=[])\n",
    "alfas = pd.DataFrame(columns=[])\n",
    "for model in [linreg, larsreg, ridgereg, lassreg, elasnet, bayreg]:\n",
    "    resul[str(model).split(\"(\")[0]] = model.coef_\n",
    "    alfas[str(model).split(\"(\")[0]] = [model.intercept_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T02:29:09.160617Z",
     "iopub.status.busy": "2021-10-21T02:29:09.160372Z",
     "iopub.status.idle": "2021-10-21T02:29:09.169994Z",
     "shell.execute_reply": "2021-10-21T02:29:09.169058Z",
     "shell.execute_reply.started": "2021-10-21T02:29:09.160590Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LinearRegression</th>\n",
       "      <th>Lars</th>\n",
       "      <th>Ridge</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>ElasticNet</th>\n",
       "      <th>BayesianRidge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.45949</td>\n",
       "      <td>36.95133</td>\n",
       "      <td>39.52662</td>\n",
       "      <td>43.14580</td>\n",
       "      <td>41.42140</td>\n",
       "      <td>27.55185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LinearRegression     Lars    Ridge    Lasso  ElasticNet  BayesianRidge\n",
       "0          36.45949 36.95133 39.52662 43.14580    41.42140       27.55185"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alfas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T02:29:40.377666Z",
     "iopub.status.busy": "2021-10-21T02:29:40.376567Z",
     "iopub.status.idle": "2021-10-21T02:29:40.397599Z",
     "shell.execute_reply": "2021-10-21T02:29:40.396822Z",
     "shell.execute_reply.started": "2021-10-21T02:29:40.377550Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LinearRegression</th>\n",
       "      <th>Lars</th>\n",
       "      <th>Ridge</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>ElasticNet</th>\n",
       "      <th>BayesianRidge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.10801</td>\n",
       "      <td>-0.10992</td>\n",
       "      <td>-0.10131</td>\n",
       "      <td>-0.03442</td>\n",
       "      <td>-0.09995</td>\n",
       "      <td>-0.10144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.04642</td>\n",
       "      <td>0.04775</td>\n",
       "      <td>0.05540</td>\n",
       "      <td>0.04128</td>\n",
       "      <td>0.05563</td>\n",
       "      <td>0.04974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02056</td>\n",
       "      <td>0.03427</td>\n",
       "      <td>-0.05245</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.05039</td>\n",
       "      <td>-0.04384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.68673</td>\n",
       "      <td>2.67396</td>\n",
       "      <td>0.42892</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.31288</td>\n",
       "      <td>1.89485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-17.76661</td>\n",
       "      <td>-18.25012</td>\n",
       "      <td>-0.15001</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.09624</td>\n",
       "      <td>-2.14193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.80987</td>\n",
       "      <td>3.80245</td>\n",
       "      <td>1.82569</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.46092</td>\n",
       "      <td>3.67401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00069</td>\n",
       "      <td>0.00098</td>\n",
       "      <td>0.00720</td>\n",
       "      <td>0.03837</td>\n",
       "      <td>0.01231</td>\n",
       "      <td>-0.01062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.47557</td>\n",
       "      <td>-1.48629</td>\n",
       "      <td>-1.08464</td>\n",
       "      <td>-0.25814</td>\n",
       "      <td>-1.00841</td>\n",
       "      <td>-1.24523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.30605</td>\n",
       "      <td>0.32042</td>\n",
       "      <td>0.32549</td>\n",
       "      <td>0.20861</td>\n",
       "      <td>0.33046</td>\n",
       "      <td>0.28022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.01233</td>\n",
       "      <td>-0.01313</td>\n",
       "      <td>-0.01632</td>\n",
       "      <td>-0.01310</td>\n",
       "      <td>-0.01659</td>\n",
       "      <td>-0.01406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.95275</td>\n",
       "      <td>-0.96037</td>\n",
       "      <td>-0.83129</td>\n",
       "      <td>-0.61916</td>\n",
       "      <td>-0.82171</td>\n",
       "      <td>-0.79726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.00931</td>\n",
       "      <td>0.00939</td>\n",
       "      <td>0.00906</td>\n",
       "      <td>0.00725</td>\n",
       "      <td>0.00879</td>\n",
       "      <td>0.01004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.52476</td>\n",
       "      <td>-0.52602</td>\n",
       "      <td>-0.69605</td>\n",
       "      <td>-0.82303</td>\n",
       "      <td>-0.72068</td>\n",
       "      <td>-0.56188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LinearRegression      Lars    Ridge    Lasso  ElasticNet  BayesianRidge\n",
       "0           -0.10801  -0.10992 -0.10131 -0.03442    -0.09995       -0.10144\n",
       "1            0.04642   0.04775  0.05540  0.04128     0.05563        0.04974\n",
       "2            0.02056   0.03427 -0.05245 -0.00000    -0.05039       -0.04384\n",
       "3            2.68673   2.67396  0.42892  0.00000     0.31288        1.89485\n",
       "4          -17.76661 -18.25012 -0.15001 -0.00000    -0.09624       -2.14193\n",
       "5            3.80987   3.80245  1.82569  0.00000     1.46092        3.67401\n",
       "6            0.00069   0.00098  0.00720  0.03837     0.01231       -0.01062\n",
       "7           -1.47557  -1.48629 -1.08464 -0.25814    -1.00841       -1.24523\n",
       "8            0.30605   0.32042  0.32549  0.20861     0.33046        0.28022\n",
       "9           -0.01233  -0.01313 -0.01632 -0.01310    -0.01659       -0.01406\n",
       "10          -0.95275  -0.96037 -0.83129 -0.61916    -0.82171       -0.79726\n",
       "11           0.00931   0.00939  0.00906  0.00725     0.00879        0.01004\n",
       "12          -0.52476  -0.52602 -0.69605 -0.82303    -0.72068       -0.56188"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:52:44.246863Z",
     "start_time": "2020-10-23T01:52:44.237637Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:29:53.101012Z",
     "iopub.status.busy": "2021-10-21T02:29:53.100200Z",
     "iopub.status.idle": "2021-10-21T02:29:53.122474Z",
     "shell.execute_reply": "2021-10-21T02:29:53.121031Z",
     "shell.execute_reply.started": "2021-10-21T02:29:53.100917Z"
    }
   },
   "outputs": [],
   "source": [
    "resul[\"features\"] = ls_pred\n",
    "resul = resul.set_index(\"features\")\n",
    "alfas[\"features\"] = [\"intercepto\"]\n",
    "alfas = alfas.set_index(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:52:46.546651Z",
     "start_time": "2020-10-23T01:52:46.538945Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:29:54.601050Z",
     "iopub.status.busy": "2021-10-21T02:29:54.599082Z",
     "iopub.status.idle": "2021-10-21T02:29:54.622145Z",
     "shell.execute_reply": "2021-10-21T02:29:54.617457Z",
     "shell.execute_reply.started": "2021-10-21T02:29:54.600938Z"
    }
   },
   "outputs": [],
   "source": [
    "resul = alfas.append(resul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:52:47.460430Z",
     "start_time": "2020-10-23T01:52:47.443630Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:30:31.753803Z",
     "iopub.status.busy": "2021-10-21T02:30:31.753061Z",
     "iopub.status.idle": "2021-10-21T02:30:31.781203Z",
     "shell.execute_reply": "2021-10-21T02:30:31.779834Z",
     "shell.execute_reply.started": "2021-10-21T02:30:31.753720Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LinearRegression</th>\n",
       "      <th>Lars</th>\n",
       "      <th>Ridge</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>ElasticNet</th>\n",
       "      <th>BayesianRidge</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>-1.47557</td>\n",
       "      <td>-1.48629</td>\n",
       "      <td>-1.08464</td>\n",
       "      <td>-0.25814</td>\n",
       "      <td>-1.00841</td>\n",
       "      <td>-1.24523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>-0.95275</td>\n",
       "      <td>-0.96037</td>\n",
       "      <td>-0.83129</td>\n",
       "      <td>-0.61916</td>\n",
       "      <td>-0.82171</td>\n",
       "      <td>-0.79726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>-0.52476</td>\n",
       "      <td>-0.52602</td>\n",
       "      <td>-0.69605</td>\n",
       "      <td>-0.82303</td>\n",
       "      <td>-0.72068</td>\n",
       "      <td>-0.56188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>-17.76661</td>\n",
       "      <td>-18.25012</td>\n",
       "      <td>-0.15001</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.09624</td>\n",
       "      <td>-2.14193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>-0.10801</td>\n",
       "      <td>-0.10992</td>\n",
       "      <td>-0.10131</td>\n",
       "      <td>-0.03442</td>\n",
       "      <td>-0.09995</td>\n",
       "      <td>-0.10144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>0.02056</td>\n",
       "      <td>0.03427</td>\n",
       "      <td>-0.05245</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.05039</td>\n",
       "      <td>-0.04384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>-0.01233</td>\n",
       "      <td>-0.01313</td>\n",
       "      <td>-0.01632</td>\n",
       "      <td>-0.01310</td>\n",
       "      <td>-0.01659</td>\n",
       "      <td>-0.01406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>0.00069</td>\n",
       "      <td>0.00098</td>\n",
       "      <td>0.00720</td>\n",
       "      <td>0.03837</td>\n",
       "      <td>0.01231</td>\n",
       "      <td>-0.01062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.00931</td>\n",
       "      <td>0.00939</td>\n",
       "      <td>0.00906</td>\n",
       "      <td>0.00725</td>\n",
       "      <td>0.00879</td>\n",
       "      <td>0.01004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>0.04642</td>\n",
       "      <td>0.04775</td>\n",
       "      <td>0.05540</td>\n",
       "      <td>0.04128</td>\n",
       "      <td>0.05563</td>\n",
       "      <td>0.04974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>0.30605</td>\n",
       "      <td>0.32042</td>\n",
       "      <td>0.32549</td>\n",
       "      <td>0.20861</td>\n",
       "      <td>0.33046</td>\n",
       "      <td>0.28022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>2.68673</td>\n",
       "      <td>2.67396</td>\n",
       "      <td>0.42892</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.31288</td>\n",
       "      <td>1.89485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>3.80987</td>\n",
       "      <td>3.80245</td>\n",
       "      <td>1.82569</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.46092</td>\n",
       "      <td>3.67401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intercepto</th>\n",
       "      <td>36.45949</td>\n",
       "      <td>36.95133</td>\n",
       "      <td>39.52662</td>\n",
       "      <td>43.14580</td>\n",
       "      <td>41.42140</td>\n",
       "      <td>27.55185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            LinearRegression      Lars    Ridge    Lasso  ElasticNet  \\\n",
       "features                                                               \n",
       "DIS                 -1.47557  -1.48629 -1.08464 -0.25814    -1.00841   \n",
       "PTRATIO             -0.95275  -0.96037 -0.83129 -0.61916    -0.82171   \n",
       "LSTAT               -0.52476  -0.52602 -0.69605 -0.82303    -0.72068   \n",
       "NOX                -17.76661 -18.25012 -0.15001 -0.00000    -0.09624   \n",
       "CRIM                -0.10801  -0.10992 -0.10131 -0.03442    -0.09995   \n",
       "INDUS                0.02056   0.03427 -0.05245 -0.00000    -0.05039   \n",
       "TAX                 -0.01233  -0.01313 -0.01632 -0.01310    -0.01659   \n",
       "AGE                  0.00069   0.00098  0.00720  0.03837     0.01231   \n",
       "B                    0.00931   0.00939  0.00906  0.00725     0.00879   \n",
       "ZN                   0.04642   0.04775  0.05540  0.04128     0.05563   \n",
       "RAD                  0.30605   0.32042  0.32549  0.20861     0.33046   \n",
       "CHAS                 2.68673   2.67396  0.42892  0.00000     0.31288   \n",
       "RM                   3.80987   3.80245  1.82569  0.00000     1.46092   \n",
       "intercepto          36.45949  36.95133 39.52662 43.14580    41.42140   \n",
       "\n",
       "            BayesianRidge  \n",
       "features                   \n",
       "DIS              -1.24523  \n",
       "PTRATIO          -0.79726  \n",
       "LSTAT            -0.56188  \n",
       "NOX              -2.14193  \n",
       "CRIM             -0.10144  \n",
       "INDUS            -0.04384  \n",
       "TAX              -0.01406  \n",
       "AGE              -0.01062  \n",
       "B                 0.01004  \n",
       "ZN                0.04974  \n",
       "RAD               0.28022  \n",
       "CHAS              1.89485  \n",
       "RM                3.67401  \n",
       "intercepto       27.55185  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resul.sort_values(by=\"Ridge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* CRIM: per capita crime rate by town\n",
    "* ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "* INDUS    proportion of non-retail business acres per town\n",
    "* CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "* NOX      nitric oxides concentration (parts per 10 million)\n",
    "* RM       average number of rooms per dwelling\n",
    "* AGE      proportion of owner-occupied units built prior to 1940\n",
    "* DIS      weighted distances to five Boston employment centres\n",
    "* RAD      index of accessibility to radial highways\n",
    "* TAX      full-value property-tax rate per \\$10,000\n",
    "* PTRATIO  pupil-teacher ratio by town\n",
    "* B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "* LSTAT    % lower status of the population\n",
    "* MEDV     Median value of owner-occupied homes in $1000's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:55:54.947288Z",
     "start_time": "2020-10-23T01:55:54.936633Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:32:14.970381Z",
     "iopub.status.busy": "2021-10-21T02:32:14.969614Z",
     "iopub.status.idle": "2021-10-21T02:32:15.017713Z",
     "shell.execute_reply": "2021-10-21T02:32:15.016779Z",
     "shell.execute_reply.started": "2021-10-21T02:32:14.970322Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   506.00000\n",
       "mean      0.55470\n",
       "std       0.11588\n",
       "min       0.38500\n",
       "25%       0.44900\n",
       "50%       0.53800\n",
       "75%       0.62400\n",
       "max       0.87100\n",
       "Name: NOX, dtype: float64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"NOX\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:55:55.495098Z",
     "start_time": "2020-10-23T01:55:55.485951Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:32:38.928640Z",
     "iopub.status.busy": "2021-10-21T02:32:38.928263Z",
     "iopub.status.idle": "2021-10-21T02:32:38.938919Z",
     "shell.execute_reply": "2021-10-21T02:32:38.938241Z",
     "shell.execute_reply.started": "2021-10-21T02:32:38.928602Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   506.00000\n",
       "mean      6.28463\n",
       "std       0.70262\n",
       "min       3.56100\n",
       "25%       5.88550\n",
       "50%       6.20850\n",
       "75%       6.62350\n",
       "max       8.78000\n",
       "Name: RM, dtype: float64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.761e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.073e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.090e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.789e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.251e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.265e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.157e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.237e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.154e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.020e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.038e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.291e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.247e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.207e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.330e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.279e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.867e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.299e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.286e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.172e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.224e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.107e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.798e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.806e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.815e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.824e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.190e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.841e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.850e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.858e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.289e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.271e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.884e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.714e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.724e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.733e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.168e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.182e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.196e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.210e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.183e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.226e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.304e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.318e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.268e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.343e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.194e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.205e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.215e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.278e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.174e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.833e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.258e+03, tolerance: 2.696e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.223e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.239e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.255e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.369e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.381e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.635e+03, tolerance: 2.895e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.834e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.111e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.238e+03, tolerance: 3.891e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.124e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "/home/oscar/VirtualEnvs/lcd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:646: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.141e+03, tolerance: 2.951e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
     ]
    }
   ],
   "source": [
    "df[\"RM\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:56:22.197696Z",
     "start_time": "2020-10-23T01:56:22.030967Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:33:37.546631Z",
     "iopub.status.busy": "2021-10-21T02:33:37.546359Z",
     "iopub.status.idle": "2021-10-21T02:33:37.553268Z",
     "shell.execute_reply": "2021-10-21T02:33:37.551993Z",
     "shell.execute_reply.started": "2021-10-21T02:33:37.546599Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.to_pickle(ridgereg, \"modelo.diplo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:56:39.083920Z",
     "start_time": "2020-10-23T01:56:39.079284Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:34:26.275614Z",
     "iopub.status.busy": "2021-10-21T02:34:26.274390Z",
     "iopub.status.idle": "2021-10-21T02:34:26.299705Z",
     "shell.execute_reply": "2021-10-21T02:34:26.296321Z",
     "shell.execute_reply.started": "2021-10-21T02:34:26.275505Z"
    }
   },
   "outputs": [],
   "source": [
    "otr_modelo = pd.read_pickle(\"modelo.diplo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T02:34:28.847851Z",
     "iopub.status.busy": "2021-10-21T02:34:28.847012Z",
     "iopub.status.idle": "2021-10-21T02:34:28.859607Z",
     "shell.execute_reply": "2021-10-21T02:34:28.858866Z",
     "shell.execute_reply.started": "2021-10-21T02:34:28.847737Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=170)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otr_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:57:31.494431Z",
     "start_time": "2020-10-23T01:57:31.490253Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:34:36.226485Z",
     "iopub.status.busy": "2021-10-21T02:34:36.223889Z",
     "iopub.status.idle": "2021-10-21T02:34:36.241674Z",
     "shell.execute_reply": "2021-10-21T02:34:36.237428Z",
     "shell.execute_reply.started": "2021-10-21T02:34:36.226362Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:59:09.154520Z",
     "start_time": "2020-10-23T01:59:09.151369Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:34:54.234394Z",
     "iopub.status.busy": "2021-10-21T02:34:54.233625Z",
     "iopub.status.idle": "2021-10-21T02:34:54.242069Z",
     "shell.execute_reply": "2021-10-21T02:34:54.240836Z",
     "shell.execute_reply.started": "2021-10-21T02:34:54.234306Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"modelo_pickle.diplo\", \"wb\") as f:\n",
    "    pickle.dump(ridgereg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:59:21.444369Z",
     "start_time": "2020-10-23T01:59:21.440767Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:35:06.979064Z",
     "iopub.status.busy": "2021-10-21T02:35:06.978678Z",
     "iopub.status.idle": "2021-10-21T02:35:06.985167Z",
     "shell.execute_reply": "2021-10-21T02:35:06.984086Z",
     "shell.execute_reply.started": "2021-10-21T02:35:06.979009Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"modelo_pickle.diplo\", \"rb\") as f:\n",
    "    otro_modelo = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:59:24.749634Z",
     "start_time": "2020-10-23T01:59:24.743216Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:35:07.247020Z",
     "iopub.status.busy": "2021-10-21T02:35:07.245915Z",
     "iopub.status.idle": "2021-10-21T02:35:07.254520Z",
     "shell.execute_reply": "2021-10-21T02:35:07.252990Z",
     "shell.execute_reply.started": "2021-10-21T02:35:07.246970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=170)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otro_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:57:03.398450Z",
     "start_time": "2020-10-23T01:57:03.391526Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:35:14.795093Z",
     "iopub.status.busy": "2021-10-21T02:35:14.794644Z",
     "iopub.status.idle": "2021-10-21T02:35:14.809741Z",
     "shell.execute_reply": "2021-10-21T02:35:14.807654Z",
     "shell.execute_reply.started": "2021-10-21T02:35:14.795023Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"y_hat\"] = otro_modelo.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T01:57:04.992721Z",
     "start_time": "2020-10-23T01:57:04.960282Z"
    },
    "execution": {
     "iopub.execute_input": "2021-10-21T02:35:16.570546Z",
     "iopub.status.busy": "2021-10-21T02:35:16.569169Z",
     "iopub.status.idle": "2021-10-21T02:35:16.627840Z",
     "shell.execute_reply": "2021-10-21T02:35:16.626830Z",
     "shell.execute_reply.started": "2021-10-21T02:35:16.570365Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "      <th>y_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>2.31000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.53800</td>\n",
       "      <td>6.57500</td>\n",
       "      <td>65.20000</td>\n",
       "      <td>4.09000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>296.00000</td>\n",
       "      <td>15.30000</td>\n",
       "      <td>396.90000</td>\n",
       "      <td>4.98000</td>\n",
       "      <td>24.00000</td>\n",
       "      <td>31.26435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>7.07000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.46900</td>\n",
       "      <td>6.42100</td>\n",
       "      <td>78.90000</td>\n",
       "      <td>4.96710</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>242.00000</td>\n",
       "      <td>17.80000</td>\n",
       "      <td>396.90000</td>\n",
       "      <td>9.14000</td>\n",
       "      <td>21.60000</td>\n",
       "      <td>25.12450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>7.07000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.46900</td>\n",
       "      <td>7.18500</td>\n",
       "      <td>61.10000</td>\n",
       "      <td>4.96710</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>242.00000</td>\n",
       "      <td>17.80000</td>\n",
       "      <td>392.83000</td>\n",
       "      <td>4.03000</td>\n",
       "      <td>34.70000</td>\n",
       "      <td>29.91116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.18000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.45800</td>\n",
       "      <td>6.99800</td>\n",
       "      <td>45.80000</td>\n",
       "      <td>6.06220</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>222.00000</td>\n",
       "      <td>18.70000</td>\n",
       "      <td>394.63000</td>\n",
       "      <td>2.94000</td>\n",
       "      <td>33.40000</td>\n",
       "      <td>29.20806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.18000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.45800</td>\n",
       "      <td>7.14700</td>\n",
       "      <td>54.20000</td>\n",
       "      <td>6.06220</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>222.00000</td>\n",
       "      <td>18.70000</td>\n",
       "      <td>396.90000</td>\n",
       "      <td>5.33000</td>\n",
       "      <td>36.20000</td>\n",
       "      <td>27.89384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>11.93000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.57300</td>\n",
       "      <td>6.59300</td>\n",
       "      <td>69.10000</td>\n",
       "      <td>2.47860</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>273.00000</td>\n",
       "      <td>21.00000</td>\n",
       "      <td>391.99000</td>\n",
       "      <td>9.67000</td>\n",
       "      <td>22.40000</td>\n",
       "      <td>23.88824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>11.93000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.57300</td>\n",
       "      <td>6.12000</td>\n",
       "      <td>76.70000</td>\n",
       "      <td>2.28750</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>273.00000</td>\n",
       "      <td>21.00000</td>\n",
       "      <td>396.90000</td>\n",
       "      <td>9.08000</td>\n",
       "      <td>20.60000</td>\n",
       "      <td>23.74358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>11.93000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.57300</td>\n",
       "      <td>6.97600</td>\n",
       "      <td>91.00000</td>\n",
       "      <td>2.16750</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>273.00000</td>\n",
       "      <td>21.00000</td>\n",
       "      <td>396.90000</td>\n",
       "      <td>5.64000</td>\n",
       "      <td>23.90000</td>\n",
       "      <td>27.93233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>11.93000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.57300</td>\n",
       "      <td>6.79400</td>\n",
       "      <td>89.30000</td>\n",
       "      <td>2.38890</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>273.00000</td>\n",
       "      <td>21.00000</td>\n",
       "      <td>393.45000</td>\n",
       "      <td>6.48000</td>\n",
       "      <td>22.00000</td>\n",
       "      <td>26.72679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>11.93000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.57300</td>\n",
       "      <td>6.03000</td>\n",
       "      <td>80.80000</td>\n",
       "      <td>2.50500</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>273.00000</td>\n",
       "      <td>21.00000</td>\n",
       "      <td>396.90000</td>\n",
       "      <td>7.88000</td>\n",
       "      <td>11.90000</td>\n",
       "      <td>24.20792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM       ZN    INDUS    CHAS     NOX      RM      AGE     DIS  \\\n",
       "0   0.00632 18.00000  2.31000 0.00000 0.53800 6.57500 65.20000 4.09000   \n",
       "1   0.02731  0.00000  7.07000 0.00000 0.46900 6.42100 78.90000 4.96710   \n",
       "2   0.02729  0.00000  7.07000 0.00000 0.46900 7.18500 61.10000 4.96710   \n",
       "3   0.03237  0.00000  2.18000 0.00000 0.45800 6.99800 45.80000 6.06220   \n",
       "4   0.06905  0.00000  2.18000 0.00000 0.45800 7.14700 54.20000 6.06220   \n",
       "..      ...      ...      ...     ...     ...     ...      ...     ...   \n",
       "501 0.06263  0.00000 11.93000 0.00000 0.57300 6.59300 69.10000 2.47860   \n",
       "502 0.04527  0.00000 11.93000 0.00000 0.57300 6.12000 76.70000 2.28750   \n",
       "503 0.06076  0.00000 11.93000 0.00000 0.57300 6.97600 91.00000 2.16750   \n",
       "504 0.10959  0.00000 11.93000 0.00000 0.57300 6.79400 89.30000 2.38890   \n",
       "505 0.04741  0.00000 11.93000 0.00000 0.57300 6.03000 80.80000 2.50500   \n",
       "\n",
       "        RAD       TAX  PTRATIO         B   LSTAT   target    y_hat  \n",
       "0   1.00000 296.00000 15.30000 396.90000 4.98000 24.00000 31.26435  \n",
       "1   2.00000 242.00000 17.80000 396.90000 9.14000 21.60000 25.12450  \n",
       "2   2.00000 242.00000 17.80000 392.83000 4.03000 34.70000 29.91116  \n",
       "3   3.00000 222.00000 18.70000 394.63000 2.94000 33.40000 29.20806  \n",
       "4   3.00000 222.00000 18.70000 396.90000 5.33000 36.20000 27.89384  \n",
       "..      ...       ...      ...       ...     ...      ...      ...  \n",
       "501 1.00000 273.00000 21.00000 391.99000 9.67000 22.40000 23.88824  \n",
       "502 1.00000 273.00000 21.00000 396.90000 9.08000 20.60000 23.74358  \n",
       "503 1.00000 273.00000 21.00000 396.90000 5.64000 23.90000 27.93233  \n",
       "504 1.00000 273.00000 21.00000 393.45000 6.48000 22.00000 26.72679  \n",
       "505 1.00000 273.00000 21.00000 396.90000 7.88000 11.90000 24.20792  \n",
       "\n",
       "[506 rows x 15 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T02:01:20.524740Z",
     "start_time": "2020-10-23T02:01:20.500146Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
